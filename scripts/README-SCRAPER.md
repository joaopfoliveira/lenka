# ğŸ›’ Continente Product Scraper

Sistema de scraping automÃ¡tico de produtos do Continente com imagens, preÃ§os e categorias.

## âš ï¸ Aviso Legal

**Este scraper Ã© para uso educacional/pessoal apenas.**

- Respeite os Termos de ServiÃ§o do Continente
- NÃ£o use para fins comerciais
- NÃ£o sobrecarregue os servidores (use delays)
- As imagens pertencem ao Continente

## ğŸ“¦ InstalaÃ§Ã£o

```bash
# Instalar dependÃªncias do scraper
npm run setup:scraper

# Ou manualmente:
npm install --save-dev puppeteer @types/puppeteer node-cron @types/node-cron
```

## ğŸš€ Como Usar

### Scraping Manual (uma vez)

```bash
npm run scrape
```

Isto vai:
1. Abrir um browser headless
2. Visitar categorias do Continente
3. Extrair produtos com imagens, preÃ§os, categorias
4. Guardar em `data/products.ts` e `data/products-scraped.json`

### Scraping AutomÃ¡tico DiÃ¡rio

```bash
npm run scrape:schedule
```

Isto vai:
- Executar scraping imediatamente
- Agendar scraping diÃ¡rio Ã s 03:00
- Continuar a correr em background

Para usar em produÃ§Ã£o, recomendo:
- PM2: `pm2 start npm --name "lenka-scraper" -- run scrape:schedule`
- Docker com cron job
- Cloud Functions (AWS Lambda, Google Cloud Functions)

## ğŸ“ Estrutura de Dados

### Produto Scraped

```typescript
{
  id: string;              // ID Ãºnico gerado
  name: string;            // Nome do produto
  price: number;           // PreÃ§o em euros
  imageUrl: string;        // URL da imagem
  store: string;           // "Continente"
  category: string;        // Categoria do produto
  brand?: string;          // Marca (quando disponÃ­vel)
  scrapedAt: string;       // Timestamp do scraping
}
```

### Categorias Configuradas

Atualmente faz scraping de:
- **Mercearia** (arroz, massas, etc)
- **LaticÃ­nios** (leite, queijo, iogurtes)
- **Bebidas** (Ã¡gua, sumos, refrigerantes)
- **Frescos** (queijos frescos, etc)

Para adicionar mais categorias, edita `scripts/scraper.ts`:

```typescript
const CATEGORIES: CategoryConfig[] = [
  {
    name: 'NovaCategoria',
    url: 'https://www.continente.pt/stores/continente/pt-pt/public/Pages/SearchResults.aspx?k=termo',
    maxProducts: 10
  }
];
```

## ğŸ”§ ConfiguraÃ§Ã£o

### Ajustar Seletores

Se o site mudar, podes precisar atualizar os seletores CSS em `scraper.ts`:

```typescript
// Procurar produtos
const productCards = document.querySelectorAll('.product, .product-card');

// Extrair nome
const nameEl = card.querySelector('.product-name, .product-title');

// Extrair preÃ§o
const priceEl = card.querySelector('.product-price, .price');
```

### Delays e Rate Limiting

```typescript
// Delay entre categorias (atualmente 2 segundos)
await new Promise(resolve => setTimeout(resolve, 2000));
```

## ğŸ› Troubleshooting

### "Nenhum produto encontrado"

**PossÃ­veis causas:**
1. Site mudou estrutura HTML â†’ Atualizar seletores
2. Cloudflare bloqueou â†’ Usar proxies/user agents diferentes
3. Timeout muito curto â†’ Aumentar `timeout` no `page.goto()`

**SoluÃ§Ã£o debug:**
```typescript
// Em scraper.ts, adicionar screenshots
await page.screenshot({ path: 'debug.png' });

// Ver HTML
const html = await page.content();
console.log(html);
```

### Imagens nÃ£o carregam

As imagens podem ser lazy-loaded. Adicionar scroll:

```typescript
await page.evaluate(() => {
  window.scrollBy(0, window.innerHeight);
});
await page.waitForTimeout(1000);
```

### Browser crashes

Aumentar memÃ³ria disponÃ­vel:

```typescript
const browser = await puppeteer.launch({
  args: ['--no-sandbox', '--disable-dev-shm-usage'],
  headless: true
});
```

## ğŸ“Š MonitorizaÃ§Ã£o

O scraper gera logs detalhados:

```
ğŸš€ Iniciando scraping do Continente...
ğŸ“¦ Scraping categoria: Mercearia
âœ… Encontrados 15 produtos em Mercearia
ğŸ“Š Resumo:
   Total de produtos: 40
   Por categoria:
      - Mercearia: 10
      - LaticÃ­nios: 10
      - Bebidas: 10
      - Frescos: 10
âœ… Guardados 40 produtos!
```

## ğŸ” Boas PrÃ¡ticas

1. **Rate Limiting**: NÃ£o fazer scraping com muita frequÃªncia
2. **User Agent**: Usar user agents realistas
3. **Respeito**: Seguir robots.txt e ToS
4. **Cache**: Guardar resultados e sÃ³ atualizar quando necessÃ¡rio
5. **Erro Handling**: Tratar erros gracefully

## ğŸš€ ProduÃ§Ã£o

### Docker

```dockerfile
FROM node:20
RUN apt-get update && apt-get install -y chromium
ENV PUPPETEER_SKIP_CHROMIUM_DOWNLOAD=true
ENV PUPPETEER_EXECUTABLE_PATH=/usr/bin/chromium
# ... resto do Dockerfile
```

### PM2 Ecosystem

```javascript
module.exports = {
  apps: [{
    name: 'lenka-scraper',
    script: 'npm',
    args: 'run scrape:schedule',
    cron_restart: '0 3 * * *'  // Reiniciar Ã s 3h
  }]
};
```

### VariÃ¡veis de Ambiente

```bash
# .env
SCRAPER_ENABLED=true
SCRAPER_SCHEDULE="0 3 * * *"
SCRAPER_MAX_PRODUCTS=50
SCRAPER_HEADLESS=true
```

## ğŸ“ˆ Melhorias Futuras

- [ ] Suporte para mÃºltiplos supermercados (Pingo Doce, Lidl)
- [ ] ComparaÃ§Ã£o de preÃ§os entre lojas
- [ ] HistÃ³rico de preÃ§os
- [ ] NotificaÃ§Ãµes quando preÃ§os descem
- [ ] API REST para aceder aos produtos
- [ ] Dashboard de administraÃ§Ã£o
- [ ] DetecÃ§Ã£o automÃ¡tica de mudanÃ§as no site

## ğŸ¤ Contribuir

Para adicionar novas funcionalidades ao scraper:

1. Testar localmente com `npm run scrape`
2. Verificar qualidade dos dados
3. Adicionar logs apropriados
4. Documentar mudanÃ§as

## ğŸ“ Suporte

Se encontrares problemas:
1. Verifica os logs
2. Testa com `headless: false` para ver o browser
3. Captura screenshots para debug
4. Verifica se o site mudou

---

**Lembra-te**: Este Ã© um projeto educacional. Usa com responsabilidade! ğŸ“

